#!/usr/bin/env python3
import os
import sys
import math
import numpy as np
from scipy import ndimage
from multiprocessing import Pool, cpu_count
from functools import partial
import time
import csv

# Try to import GDAL, fallback if not available
try:
    from osgeo import gdal
    HAS_GDAL = True
except ImportError:
    HAS_GDAL = False
    print("Warning: GDAL not available, some functions may not work")

def load_target_tiles(csv_file):
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å¯¾è±¡ã‚¿ã‚¤ãƒ«IDã‚’èª­ã¿è¾¼ã¿"""
    target_tiles = {}  # {zoom: set((x, y))}
    
    if not os.path.exists(csv_file):
        print(f"Warning: Target tiles CSV file not found: {csv_file}")
        return None
    
    try:
        with open(csv_file, 'r') as f:
            reader = csv.DictReader(f)
            for row in reader:
                z = int(row['z'])
                x = int(row['x'])
                y = int(row['y'])
                
                if z not in target_tiles:
                    target_tiles[z] = set()
                target_tiles[z].add((x, y))
        
        # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
        total_tiles = sum(len(tiles) for tiles in target_tiles.values())
        print(f"ğŸ“„ Loaded target tiles from {csv_file}")
        print(f"   Total target tiles: {total_tiles}")
        for zoom in sorted(target_tiles.keys()):
            print(f"   z{zoom}: {len(target_tiles[zoom])} tiles")
        
        return target_tiles
        
    except Exception as e:
        print(f"Error loading target tiles CSV: {e}")
        return None

def deg2num(lat_deg, lon_deg, zoom):
    """ç·¯åº¦çµŒåº¦ã‚’ã‚¿ã‚¤ãƒ«åº§æ¨™ã«å¤‰æ›"""
    lat_rad = math.radians(lat_deg)
    n = 2.0 ** zoom
    xtile = int((lon_deg + 180.0) / 360.0 * n)
    ytile = int((1.0 - math.asinh(math.tan(lat_rad)) / math.pi) / 2.0 * n)
    return (xtile, ytile)

def num2deg(xtile, ytile, zoom):
    """ã‚¿ã‚¤ãƒ«åº§æ¨™ã‚’ç·¯åº¦çµŒåº¦ã«å¤‰æ›"""
    n = 2.0 ** zoom
    lon_deg = xtile / n * 360.0 - 180.0
    lat_rad = math.atan(math.sinh(math.pi * (1 - 2 * ytile / n)))
    lat_deg = math.degrees(lat_rad)
    return (lat_deg, lon_deg)

def bilinear_interpolation(data, x, y, width, height):
    """ãƒã‚¤ãƒªãƒ‹ã‚¢è£œé–“ã§æ¨™é«˜å€¤ã‚’å–å¾—"""
    # åº§æ¨™ã®æ•´æ•°éƒ¨åˆ†ã¨å°æ•°éƒ¨åˆ†ã‚’å–å¾—
    x1 = int(np.floor(x))
    y1 = int(np.floor(y))
    x2 = min(x1 + 1, width - 1)
    y2 = min(y1 + 1, height - 1)
    
    # ç¯„å›²ãƒã‚§ãƒƒã‚¯
    if x1 < 0 or y1 < 0 or x1 >= width or y1 >= height:
        return np.nan
    
    # å°æ•°éƒ¨åˆ†
    dx = x - x1
    dy = y - y1
    
    # 4ã¤ã®è§’ã®å€¤ã‚’å–å¾—
    try:
        v11 = data[y1, x1]  # å·¦ä¸Š
        v21 = data[y1, x2]  # å³ä¸Š
        v12 = data[y2, x1]  # å·¦ä¸‹
        v22 = data[y2, x2]  # å³ä¸‹
        
        # NaNãƒã‚§ãƒƒã‚¯
        if np.isnan(v11) or np.isnan(v21) or np.isnan(v12) or np.isnan(v22):
            # ä¸€éƒ¨ã§ã‚‚NaNãŒã‚ã‚‹å ´åˆã¯æœ€è¿‘å‚ã‚’ä½¿ç”¨
            if dx < 0.5 and dy < 0.5:
                return v11
            elif dx >= 0.5 and dy < 0.5:
                return v21
            elif dx < 0.5 and dy >= 0.5:
                return v12
            else:
                return v22
        
        # ãƒã‚¤ãƒªãƒ‹ã‚¢è£œé–“ã‚’å®Ÿè¡Œ
        # ä¸Šè¾ºã®è£œé–“
        v_top = v11 * (1 - dx) + v21 * dx
        # ä¸‹è¾ºã®è£œé–“
        v_bottom = v12 * (1 - dx) + v22 * dx
        # ç¸¦æ–¹å‘ã®è£œé–“
        result = v_top * (1 - dy) + v_bottom * dy
        
        return result
        
    except IndexError:
        return np.nan

def load_tile_data(tile_file):
    """ã‚¿ã‚¤ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    if not os.path.exists(tile_file):
        return None
    
    try:
        with open(tile_file, 'r') as f:
            lines = f.readlines()
        
        data = []
        for line in lines:
            row = [float(x) for x in line.strip().split(',')]
            data.append(row)
        
        return np.array(data, dtype=np.float32)
    except:
        return None

def save_tile_data(data, tile_file):
    """ã‚¿ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    os.makedirs(os.path.dirname(tile_file), exist_ok=True)
    
    with open(tile_file, 'w') as f:
        for row in range(data.shape[0]):
            row_values = [f"{data[row, col]:.2f}" for col in range(data.shape[1])]
            f.write(','.join(row_values))
            f.write('\n')

def downsample_tile(parent_tiles, tile_size):
    """4ã¤ã®è¦ªã‚¿ã‚¤ãƒ«ã‹ã‚‰1ã¤ã®å­ã‚¿ã‚¤ãƒ«ã‚’ãƒã‚¤ãƒªãƒ‹ã‚¢ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§ç”Ÿæˆ"""
    # 4ã¤ã®è¦ªã‚¿ã‚¤ãƒ«ã‚’çµåˆã—ã¦2x2ã®ã‚¿ã‚¤ãƒ«é…ç½®ã‚’ä½œæˆ
    top_row = np.hstack([parent_tiles[0], parent_tiles[1]])  # å·¦ä¸Š, å³ä¸Š
    bottom_row = np.hstack([parent_tiles[2], parent_tiles[3]])  # å·¦ä¸‹, å³ä¸‹
    combined = np.vstack([top_row, bottom_row])
    
    # ãƒã‚¤ãƒªãƒ‹ã‚¢è£œé–“ã§ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    zoom_factor = tile_size / combined.shape[0]
    downsampled = ndimage.zoom(combined, zoom_factor, order=1)  # order=1ã¯ãƒã‚¤ãƒªãƒ‹ã‚¢è£œé–“
    
    # æ­£ç¢ºãªã‚¿ã‚¤ãƒ«ã‚µã‚¤ã‚ºã«èª¿æ•´
    if downsampled.shape[0] != tile_size or downsampled.shape[1] != tile_size:
        # ã‚¯ãƒ­ãƒƒãƒ”ãƒ³ã‚°ã¾ãŸã¯ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
        result = np.zeros((tile_size, tile_size), dtype=np.float32)
        min_h = min(downsampled.shape[0], tile_size)
        min_w = min(downsampled.shape[1], tile_size)
        result[:min_h, :min_w] = downsampled[:min_h, :min_w]
        return result
    
    return downsampled

def generate_text_tiles(input_file, output_dir, min_zoom, max_zoom, tile_size, num_processes=None, target_tiles_csv=None):
    """ãƒ†ã‚­ã‚¹ãƒˆã‚¿ã‚¤ãƒ«ã‚’ç”Ÿæˆï¼ˆãƒ”ãƒ©ãƒŸãƒƒãƒ‰æ–¹å¼ï¼šz14ã‹ã‚‰é–‹å§‹ã—ã¦ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰"""
    if not HAS_GDAL:
        print("Error: GDAL is required for this function")
        return False
    
    if num_processes is None:
        num_processes = min(cpu_count(), 8)  # æœ€å¤§8ãƒ—ãƒ­ã‚»ã‚¹
    
    # å¯¾è±¡ã‚¿ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    target_tiles = None
    if target_tiles_csv:
        target_tiles = load_target_tiles(target_tiles_csv)
        if target_tiles is None:
            print("Warning: Failed to load target tiles, proceeding with full tile generation")
    
    print(f"ğŸš€ Starting text tile generation with {num_processes} processes")
    if target_tiles:
        print(f"ğŸ¯ Using target tiles from: {target_tiles_csv}")
    print(f"Opening raster: {input_file}")
    dataset = gdal.Open(input_file, gdal.GA_ReadOnly)
    if not dataset:
        print(f"Error: Could not open {input_file}")
        return False
    
    # ãƒ©ã‚¹ã‚¿ãƒ¼ã®æƒ…å ±ã‚’å–å¾—
    geotransform = dataset.GetGeoTransform()
    band = dataset.GetRasterBand(1)
    nodata_value = band.GetNoDataValue()
    
    print(f"Raster size: {dataset.RasterXSize} x {dataset.RasterYSize}")
    print(f"Geotransform: {geotransform}")
    print(f"NoData value: {nodata_value}")
    
    # Web Mercator EPSG:3857ã®ç¯„å›²ã‚’å–å¾—
    minx = geotransform[0]
    maxy = geotransform[3]
    maxx = minx + geotransform[1] * dataset.RasterXSize
    miny = maxy + geotransform[5] * dataset.RasterYSize
    
    print(f"Raster bounds (Web Mercator): {minx}, {miny}, {maxx}, {maxy}")
    
    # Web Mercatorã‹ã‚‰ç·¯åº¦çµŒåº¦ã«å¤‰æ›
    def webmercator_to_wgs84(x, y):
        lon = x * 180.0 / 20037508.342789244
        lat = math.atan(math.exp(y * math.pi / 20037508.342789244)) * 360.0 / math.pi - 90.0
        return lat, lon
    
    min_lat, min_lon = webmercator_to_wgs84(minx, miny)
    max_lat, max_lon = webmercator_to_wgs84(maxx, maxy)
    
    print(f"Raster bounds (WGS84): {min_lat}, {min_lon}, {max_lat}, {max_lon}")
    
    total_tiles = 0
    total_start_time = time.time()
    
    # Step 1: æœ€é«˜è§£åƒåº¦ï¼ˆmax_zoomã€é€šå¸¸z14ï¼‰ã®ã‚¿ã‚¤ãƒ«ã‚’ç”Ÿæˆ
    print(f"ğŸš€ Generating base tiles at zoom level {max_zoom}")
    base_start_time = time.time()
    base_zoom_tiles = generate_base_zoom_tiles(
        dataset, band, geotransform, nodata_value,
        minx, miny, maxx, maxy, min_lat, min_lon, max_lat, max_lon,
        max_zoom, tile_size, output_dir, num_processes, target_tiles
    )
    base_end_time = time.time()
    total_tiles += base_zoom_tiles
    print(f"âœ… Generated {base_zoom_tiles} base tiles at zoom {max_zoom} in {base_end_time - base_start_time:.1f}s")
    
    # Step 2: ãƒ”ãƒ©ãƒŸãƒƒãƒ‰ç”Ÿæˆï¼ˆmax_zoom-1ã‹ã‚‰min_zoomã¾ã§ï¼‰
    for zoom in range(max_zoom - 1, min_zoom - 1, -1):
        print(f"ğŸ”„ Generating zoom level {zoom} from zoom {zoom + 1}")
        pyramid_start_time = time.time()
        pyramid_tiles = generate_pyramid_level(output_dir, zoom, zoom + 1, tile_size, target_tiles)
        pyramid_end_time = time.time()
        total_tiles += pyramid_tiles
        print(f"âœ… Generated {pyramid_tiles} tiles for zoom {zoom} in {pyramid_end_time - pyramid_start_time:.1f}s")
    
    total_end_time = time.time()
    total_time = total_end_time - total_start_time
    
    print(f"ğŸ‰ Total tiles generated: {total_tiles} in {total_time:.1f}s")
    print(f"ğŸ“Š Average processing speed: {total_tiles / total_time:.1f} tiles/second")
    dataset = None
    return True

def generate_single_base_tile(args):
    """å˜ä¸€ã®ãƒ™ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ«ã‚’ç”Ÿæˆï¼ˆãƒãƒ«ãƒãƒ—ãƒ­ã‚»ãƒƒã‚·ãƒ³ã‚°ç”¨ï¼‰"""
    (tx, ty, zoom, tile_size, input_file, output_dir, 
     geotransform, nodata_value, minx, miny, maxx, maxy) = args
    
    try:
        # GDALãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å†ã‚ªãƒ¼ãƒ—ãƒ³
        dataset = gdal.Open(input_file, gdal.GA_ReadOnly)
        if not dataset:
            return (tx, ty, False, "Could not open dataset")
        
        band = dataset.GetRasterBand(1)
        
        # ã‚¿ã‚¤ãƒ«ã®åœ°ç†çš„ç¯„å›²ã‚’è¨ˆç®—ï¼ˆWGS84ï¼‰
        north, west = num2deg(tx, ty, zoom)
        south, east = num2deg(tx + 1, ty + 1, zoom)
        
        # WGS84ã‹ã‚‰Web Mercatorã«å¤‰æ›
        def wgs84_to_webmercator(lat, lon):
            x = lon * 20037508.342789244 / 180.0
            y = math.log(math.tan((90.0 + lat) * math.pi / 360.0)) * 20037508.342789244 / math.pi
            return x, y
        
        tile_west_merc, tile_north_merc = wgs84_to_webmercator(north, west)
        tile_east_merc, tile_south_merc = wgs84_to_webmercator(south, east)
        
        # ã‚¿ã‚¤ãƒ«ã¨ãƒ©ã‚¹ã‚¿ãƒ¼ã®é‡è¤‡é ˜åŸŸã‚’è¨ˆç®—
        overlap_minx = max(tile_west_merc, minx)
        overlap_maxx = min(tile_east_merc, maxx)
        overlap_miny = max(tile_south_merc, miny)
        overlap_maxy = min(tile_north_merc, maxy)
        
        # é‡è¤‡ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if overlap_minx >= overlap_maxx or overlap_miny >= overlap_maxy:
            dataset = None
            return (tx, ty, False, "No overlap")
        
        # ãƒ©ã‚¹ã‚¿ãƒ¼åº§æ¨™ç³»ã§ã®ç¯„å›²ã‚’è¨ˆç®—
        pixel_minx = max(0, int((overlap_minx - geotransform[0]) / geotransform[1]))
        pixel_maxx = min(dataset.RasterXSize, int((overlap_maxx - geotransform[0]) / geotransform[1]) + 1)
        pixel_miny = max(0, int((overlap_maxy - geotransform[3]) / geotransform[5]))
        pixel_maxy = min(dataset.RasterYSize, int((overlap_miny - geotransform[3]) / geotransform[5]) + 1)
        
        if pixel_minx >= pixel_maxx or pixel_miny >= pixel_maxy:
            dataset = None
            return (tx, ty, False, "Invalid pixel range")
        
        # ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        width = pixel_maxx - pixel_minx
        height = pixel_maxy - pixel_miny
        
        if width <= 0 or height <= 0:
            dataset = None
            return (tx, ty, False, "Invalid dimensions")
        
        data = band.ReadAsArray(pixel_minx, pixel_miny, width, height)
        
        if data is None:
            dataset = None
            return (tx, ty, False, "Could not read data")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’floatå‹ã«å¤‰æ›
        data = data.astype(np.float32)
        
        # NaNã‚„ç„¡åŠ¹å€¤ã‚’å‡¦ç†
        if nodata_value is not None:
            data = np.where(data == nodata_value, np.nan, data)
        
        # ã‚¿ã‚¤ãƒ«å†…ã§ã®ã‚°ãƒªãƒƒãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ç”Ÿæˆ
        elevation_grid = np.full((tile_size, tile_size), np.nan, dtype=np.float32)
        
        for i in range(tile_size):
            for j in range(tile_size):
                # ã‚°ãƒªãƒƒãƒ‰ãƒã‚¤ãƒ³ãƒˆã®åœ°ç†çš„åº§æ¨™ï¼ˆWGS84ï¼‰
                point_lat = north - (north - south) * i / (tile_size - 1)
                point_lon = west + (east - west) * j / (tile_size - 1)
                
                # Web Mercatoråº§æ¨™ã«å¤‰æ›
                point_x, point_y = wgs84_to_webmercator(point_lat, point_lon)
                
                # ãƒ©ã‚¹ã‚¿ãƒ¼åº§æ¨™ç³»ã«å¤‰æ›
                raster_x = (point_x - geotransform[0]) / geotransform[1]
                raster_y = (point_y - geotransform[3]) / geotransform[5]
                
                # ãƒ©ã‚¹ã‚¿ãƒ¼ç¯„å›²å†…ã‹ãƒã‚§ãƒƒã‚¯
                if (pixel_minx <= raster_x < pixel_maxx and 
                    pixel_miny <= raster_y < pixel_maxy):
                    
                    # ãƒ­ãƒ¼ã‚«ãƒ«åº§æ¨™ã«å¤‰æ›ï¼ˆbilinearè£œé–“ç”¨ï¼‰
                    local_x = raster_x - pixel_minx
                    local_y = raster_y - pixel_miny
                    
                    # Bilinearè£œé–“ã‚’å®Ÿè¡Œ
                    value = bilinear_interpolation(data, local_x, local_y, width, height)
                    if not np.isnan(value):
                        elevation_grid[i, j] = value
        
        # NaNã‚’0ã«å¤‰æ›
        elevation_grid = np.where(np.isnan(elevation_grid), 0.0, elevation_grid)
        
        # å…¨é¢0.00ã®å ´åˆã¯ã‚¿ã‚¤ãƒ«å‡ºåŠ›ã‚’ã‚¹ã‚­ãƒƒãƒ—
        if np.all(elevation_grid == 0.0):
            dataset = None
            return (tx, ty, False, "All zeros")
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        x_dir = os.path.join(output_dir, str(zoom), str(tx))
        os.makedirs(x_dir, exist_ok=True)
        tile_file = os.path.join(x_dir, f"{ty}.txt")
        save_tile_data(elevation_grid, tile_file)
        
        dataset = None
        return (tx, ty, True, "Success")
        
    except Exception as e:
        return (tx, ty, False, f"Error: {str(e)}")

def generate_base_zoom_tiles(dataset, band, geotransform, nodata_value,
                           minx, miny, maxx, maxy, min_lat, min_lon, max_lat, max_lon,
                           zoom, tile_size, output_dir, num_processes=None, target_tiles=None):
    """æœ€é«˜è§£åƒåº¦ã®ã‚¿ã‚¤ãƒ«ã‚’å…ƒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä¸¦åˆ—å‡¦ç†ã§ç”Ÿæˆ"""
    
    if num_processes is None:
        num_processes = min(cpu_count(), 8)  # æœ€å¤§8ãƒ—ãƒ­ã‚»ã‚¹
    
    print(f"  Using {num_processes} processes for parallel tile generation")
    
    # ã“ã®ã‚ºãƒ¼ãƒ ãƒ¬ãƒ™ãƒ«ã§ã®ã‚¿ã‚¤ãƒ«ç¯„å›²ã‚’è¨ˆç®—ï¼ˆå¸¸ã«å®Ÿè¡Œï¼‰
    min_tile_x, max_tile_y = deg2num(min_lat, min_lon, zoom)
    max_tile_x, min_tile_y = deg2num(max_lat, max_lon, zoom)
    
    # ã‚¿ã‚¤ãƒ«ç¯„å›²ã‚’èª¿æ•´
    min_tile_x = max(0, min_tile_x)
    max_tile_x = min(2**zoom - 1, max_tile_x)
    min_tile_y = max(0, min_tile_y)
    max_tile_y = min(2**zoom - 1, max_tile_y)
    
    print(f"  Tile range: x={min_tile_x}-{max_tile_x}, y={min_tile_y}-{max_tile_y}")
    
    # ãƒ©ã‚¹ã‚¿ç¯„å›²å†…ã®å…¨ã‚¿ã‚¤ãƒ«åº§æ¨™ã®ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆ
    raster_tile_coords = []
    for tx in range(min_tile_x, max_tile_x + 1):
        for ty in range(min_tile_y, max_tile_y + 1):
            raster_tile_coords.append((tx, ty))
    
    # å¯¾è±¡ã‚¿ã‚¤ãƒ«ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯äº¤é›†åˆã‚’å–ã‚‹
    if target_tiles and zoom in target_tiles:
        target_tile_set = target_tiles[zoom]
        tile_coords = [(tx, ty) for tx, ty in raster_tile_coords if (tx, ty) in target_tile_set]
        print(f"  Raster tiles: {len(raster_tile_coords)}, Target tiles: {len(target_tile_set)}, Intersection: {len(tile_coords)} tiles")
    else:
        tile_coords = raster_tile_coords
        print(f"  Processing all {len(tile_coords)} tiles in raster range")
    
    zoom_dir = os.path.join(output_dir, str(zoom))
    os.makedirs(zoom_dir, exist_ok=True)
    
    # å…¨ã‚¿ã‚¤ãƒ«ã®ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆã‚’ä½œæˆ
    tasks = []
    for tx, ty in tile_coords:
        task = (tx, ty, zoom, tile_size, dataset.GetDescription(), output_dir,
               geotransform, nodata_value, minx, miny, maxx, maxy)
        tasks.append(task)
    
    total_tasks = len(tasks)
    print(f"  Processing {total_tasks} tiles...")
    
    successful_tiles = 0
    failed_tiles = 0
    skipped_tiles = 0
    
    start_time = time.time()
    
    # ä¸¦åˆ—å‡¦ç†ã§ã‚¿ã‚¤ãƒ«ç”Ÿæˆ
    with Pool(processes=num_processes) as pool:
        # é€²æ—è¡¨ç¤ºã®ãŸã‚ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã‚’èª¿æ•´
        chunk_size = max(1, total_tasks // (num_processes * 4))
        
        results = pool.map(generate_single_base_tile, tasks, chunksize=chunk_size)
        
        # çµæœã‚’å‡¦ç†
        for i, (tx, ty, success, message) in enumerate(results):
            if success:
                successful_tiles += 1
            elif message == "No overlap" or message == "All zeros":
                skipped_tiles += 1
            else:
                failed_tiles += 1
                if failed_tiles <= 10:  # æœ€åˆã®10å€‹ã®ã‚¨ãƒ©ãƒ¼ã®ã¿è¡¨ç¤º
                    print(f"    Failed tile {tx}/{ty}: {message}")
            
            # é€²æ—è¡¨ç¤ºï¼ˆ100ã‚¿ã‚¤ãƒ«ã”ã¨ï¼‰
            if (i + 1) % 100 == 0 or i + 1 == total_tasks:
                elapsed = time.time() - start_time
                progress = (i + 1) / total_tasks * 100
                eta = elapsed / (i + 1) * (total_tasks - i - 1) if i > 0 else 0
                print(f"    Progress: {i+1}/{total_tasks} ({progress:.1f}%) - "
                      f"Success: {successful_tiles}, Skipped: {skipped_tiles}, Failed: {failed_tiles} - "
                      f"ETA: {eta:.1f}s")
    
    end_time = time.time()
    total_time = end_time - start_time
    
    print(f"  Completed in {total_time:.1f}s")
    print(f"  Results: {successful_tiles} successful, {skipped_tiles} skipped, {failed_tiles} failed")
    
    return successful_tiles

def generate_pyramid_level(output_dir, target_zoom, source_zoom, tile_size, target_tiles=None):
    """è¦ªã‚ºãƒ¼ãƒ ãƒ¬ãƒ™ãƒ«ã‹ã‚‰å­ã‚ºãƒ¼ãƒ ãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒ«ã‚’ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§ç”Ÿæˆ"""
    
    source_dir = os.path.join(output_dir, str(source_zoom))
    target_dir = os.path.join(output_dir, str(target_zoom))
    
    if not os.path.exists(source_dir):
        print(f"  Warning: Source zoom directory {source_dir} does not exist")
        return 0
    
    os.makedirs(target_dir, exist_ok=True)
    
    # ã‚½ãƒ¼ã‚¹ã‚ºãƒ¼ãƒ ãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
    source_tiles = set()
    for x_dir_name in os.listdir(source_dir):
        x_dir_path = os.path.join(source_dir, x_dir_name)
        if os.path.isdir(x_dir_path):
            try:
                tx = int(x_dir_name)
                for tile_file in os.listdir(x_dir_path):
                    if tile_file.endswith('.txt'):
                        ty = int(tile_file[:-4])  # .txtã‚’é™¤å»
                        source_tiles.add((tx, ty))
            except ValueError:
                continue
    
    print(f"  Found {len(source_tiles)} source tiles at zoom {source_zoom}")
    
    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚ºãƒ¼ãƒ ãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒ«ç¯„å›²ã‚’è¨ˆç®—
    if target_tiles and target_zoom in target_tiles:
        # CSVã§æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¤ãƒ«ã®ã¿ã‚’å¯¾è±¡ã¨ã™ã‚‹
        target_tiles_coords = target_tiles[target_zoom]
        print(f"  Using target tiles from CSV: {len(target_tiles_coords)} tiles at zoom {target_zoom}")
    else:
        # ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ«ã‹ã‚‰è¨ˆç®—
        target_tiles_coords = set()
        for source_tx, source_ty in source_tiles:
            # è¦ªã‚¿ã‚¤ãƒ«ã‹ã‚‰å­ã‚¿ã‚¤ãƒ«ã®åº§æ¨™ã‚’è¨ˆç®—
            target_tx = source_tx // 2
            target_ty = source_ty // 2
            target_tiles_coords.add((target_tx, target_ty))
    
    print(f"  Generating {len(target_tiles_coords)} target tiles at zoom {target_zoom}")
    
    generated_count = 0
    
    for target_tx, target_ty in target_tiles_coords:
        # 4ã¤ã®è¦ªã‚¿ã‚¤ãƒ«ã®åº§æ¨™
        parent_tiles_coords = [
            (target_tx * 2, target_ty * 2),        # å·¦ä¸Š
            (target_tx * 2 + 1, target_ty * 2),    # å³ä¸Š
            (target_tx * 2, target_ty * 2 + 1),    # å·¦ä¸‹
            (target_tx * 2 + 1, target_ty * 2 + 1) # å³ä¸‹
        ]
        
        # è¦ªã‚¿ã‚¤ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        parent_tiles = []
        all_loaded = True
        
        for ptx, pty in parent_tiles_coords:
            parent_file = os.path.join(source_dir, str(ptx), f"{pty}.txt")
            parent_data = load_tile_data(parent_file)
            
            if parent_data is not None:
                parent_tiles.append(parent_data)
            else:
                # å­˜åœ¨ã—ãªã„è¦ªã‚¿ã‚¤ãƒ«ã¯0ã§åŸ‹ã‚ã‚‹
                parent_tiles.append(np.zeros((tile_size, tile_size), dtype=np.float32))
        
        if len(parent_tiles) == 4:
            # ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å®Ÿè¡Œ
            downsampled = downsample_tile(parent_tiles, tile_size)
            
            # å…¨é¢0.00ã®å ´åˆã¯ã‚¿ã‚¤ãƒ«å‡ºåŠ›ã‚’ã‚¹ã‚­ãƒƒãƒ—
            if np.all(downsampled == 0.0):
                continue
            
            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¿ã‚¤ãƒ«ã‚’ä¿å­˜
            target_x_dir = os.path.join(target_dir, str(target_tx))
            target_file = os.path.join(target_x_dir, f"{target_ty}.txt")
            save_tile_data(downsampled, target_file)
            
            generated_count += 1
    
    return generated_count

if __name__ == "__main__":
    if len(sys.argv) < 6 or len(sys.argv) > 8:
        print("Usage: python3 generate_text_tiles.py <input_file> <output_dir> <min_zoom> <max_zoom> <tile_size> [num_processes] [target_tiles_csv]")
        print("  num_processes: Number of parallel processes (default: auto-detect, max 8)")
        print("  target_tiles_csv: CSV file with target tile IDs (z,x,y format)")
        sys.exit(1)
    
    input_file = sys.argv[1]
    output_dir = sys.argv[2]
    min_zoom = int(sys.argv[3])
    max_zoom = int(sys.argv[4])
    tile_size = int(sys.argv[5])
    
    num_processes = None
    if len(sys.argv) >= 7:
        try:
            num_processes = int(sys.argv[6])
            if num_processes <= 0:
                print("Error: num_processes must be positive")
                sys.exit(1)
        except ValueError:
            # 6ç•ªç›®ã®å¼•æ•°ãŒCSVãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
            target_tiles_csv = sys.argv[6]
            num_processes = None
    
    target_tiles_csv = None
    if len(sys.argv) == 8:
        target_tiles_csv = sys.argv[7]
    elif len(sys.argv) == 7 and not sys.argv[6].isdigit():
        target_tiles_csv = sys.argv[6]
        num_processes = None
    
    success = generate_text_tiles(input_file, output_dir, min_zoom, max_zoom, tile_size, num_processes, target_tiles_csv)
    if not success:
        sys.exit(1)